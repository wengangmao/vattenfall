{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXnCHrPqfMqL"
   },
   "source": [
    "# Static modelling\n",
    "\n",
    "<ul>\n",
    "<li>Explore statistical correlation between different parameters</li>\n",
    "<li>ML to get static condition</li>\n",
    "<li>Deep learning to test $Head$ in terms of pump speed and  $head$</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R0RA82WVfDn4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "# plt.style.use(['science','no-latex'])\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A. Load data from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20938,
     "status": "ok",
     "timestamp": 1631647599627,
     "user": {
      "displayName": "mao wengang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13681190246989215896"
     },
     "user_tz": -120
    },
    "id": "UDikXTt4xeg9",
    "outputId": "179d3721-7964-4f80-e276-4c4b79411f28"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fvjui9wIxheX"
   },
   "source": [
    "## 1B. Load data from local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iR3aak1W6El"
   },
   "outputs": [],
   "source": [
    "#import io\n",
    "#df = pd.read_csv(io.StringIO(uploaded['vattenfall_turbine.csv'].decode('utf-8')))\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\wengang\\OneDrive - Chalmers\\2021_Vattenfall\\vattenfall_turbine.csv')\n",
    "keys = df.dtypes.index[1:11]\n",
    "df_data = df[df.dtypes.index[1:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 17557,
     "status": "ok",
     "timestamp": 1631606046584,
     "user": {
      "displayName": "mao wengang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13681190246989215896"
     },
     "user_tz": -120
    },
    "id": "DSDmMEDlPnWb",
    "outputId": "a89f1098-b26a-4408-b082-ef02ef2e6555"
   },
   "outputs": [],
   "source": [
    "df_data.plot(subplots=True)\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "executionInfo": {
     "elapsed": 91787,
     "status": "ok",
     "timestamp": 1631606147371,
     "user": {
      "displayName": "mao wengang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "13681190246989215896"
     },
     "user_tz": -120
    },
    "id": "GBZ7pjroPnWb",
    "outputId": "1f5dc10b-51ff-478b-8481-b96c98bc8aa3"
   },
   "outputs": [],
   "source": [
    "#sns.lmplot(df.dtypes.index[1],df.dtypes.index[2], data=df, fit_reg=False)\n",
    "\n",
    "sns.heatmap(df_data.corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()\n",
    "\n",
    "sns.jointplot(data=df_data, x='pump102_speed', y='pump101_speed', kind='reg', color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vC6_ENogPnWc"
   },
   "source": [
    "## 2, Use various static ML methods to derive models for Head_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1, XGBoost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for the data\n",
    "df_data.dropna()\n",
    "resolution = 100\n",
    "df_data1 = df_data.iloc[::resolution]\n",
    "\n",
    "df_features = df_data1[df_data.keys()[[0, 2, 3, 8]]]\n",
    "df_target = df_data1[['head_gross']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_target, test_size = 0.2)\n",
    "y_test = np.sort(y_test)\n",
    "\n",
    "# Find the optimal parameters for the XGBoost modelling\n",
    "params_fix = {'objective':'reg:squarederror', \n",
    "              'nthread': -1, \n",
    "              'colsample_bytree': 0.99, \n",
    "              'min_child_weight': 5.0, \n",
    "              'n_estimators': 100\n",
    "    }\n",
    "params = {'learning_rate': [0.1, 0.15],\n",
    "        'gamma': [5, 6, 7],\n",
    "        #'reg_alpha': 149.79,\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'max_depth': [16, 19]\n",
    "    }\n",
    "\n",
    "params_best = {'learning_rate': 0.15,\n",
    "        'gamma': 5,\n",
    "        #'reg_alpha': 149.79,\n",
    "        'subsample': 0.9,\n",
    "        'max_depth': 16\n",
    "    }\n",
    "\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(**params_fix)\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "xgb_models = GridSearchCV(xgb_reg, params).fit(X_train,y_train)\n",
    "params_best = xgb_models.best_params_\n",
    "end = time.time()\n",
    "time_cost = end - start\n",
    "print(f'The time used to find the optimal solution is {time_cost} seconds')\n",
    "\n",
    "\n",
    "# Print the best model parameters: NB one should use it in the following analysis\n",
    "xgb_models.fit(X_train, y_train)\n",
    "print(xgb_models.best_score_)\n",
    "print(xgb_models.best_params_)\n",
    "\n",
    "# Use best parameters to fit the XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(max_depth = 16, learning_rate = 0.1, gamma= 0, subsample=0.8, colsample_bytree = 0.1, n_estimators = 1000)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prediction and model assessment by MSE and R2\n",
    "predictions_xgb = model_xgb.predict(X_test)\n",
    "mse_xgb = mean_squared_error(predictions_xgb,y_test)\n",
    "r2_xgb = r2_score(predictions_xgb,y_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.plot(predictions_xgb, label = \"XGBoost with tuned params\")\n",
    "plt.plot(y_test,'-o',  label = \"Data\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: OPTIONAL -- save results to Mat file for better plotting\n",
    "from scipy import io\n",
    "head_obs_all = df_target.values\n",
    "head_pre_all = model.predict(df_train)\n",
    "\n",
    "head_obs_test = y_test.values\n",
    "head_pre_test = model.predict(X_test)\n",
    "io.savemat('xgboost_head.mat', {'head_obs_all':head_obs_all,'head_pre_all':head_pre_all,'head_obs_test':head_obs_test,'head_pre_test':head_pre_test})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2, Neural Network Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn = MLPRegressor(hidden_layer_sizes=(50,),solver =\"lbfgs\", random_state=9)\n",
    "\n",
    "model_nn.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "predictions_nn = model_nn.predict(X_test)\n",
    "\n",
    "error_nn = mean_squared_error(predictions_nn, y_test)\n",
    "\n",
    "\n",
    "# Prediction and model assessment by MSE and R2\n",
    "mse_nn = mean_squared_error(predictions_nn,y_test)\n",
    "r2_nn = r2_score(predictions_nn,y_test)\n",
    "\n",
    "#### Plots of results ####\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(y_test,'-o',  label = \"Data\")\n",
    "\n",
    "plt.plot(predictions_nn,'-*', label = \"Neural Network\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.3, Ada random forest model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ada Boosted Decision Tree ####\n",
    "\n",
    "# Initialize the model with some parameters.\n",
    "model_ada = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=300)\n",
    "# Fit the model to the data.\n",
    "model_ada.fit(X_train,y_train.values.ravel())\n",
    "# Make predictions.\n",
    "predictions_ada = model_ada.predict(X_test)\n",
    "# Compute the error.\n",
    "error_ada = mean_squared_error(predictions_ada, y_test)\n",
    "\n",
    "\n",
    "# Prediction and model assessment by MSE and R2\n",
    "mse_ada = mean_squared_error(predictions_ada,y_test)\n",
    "r2_ada = r2_score(predictions_ada,y_test)\n",
    "\n",
    "\n",
    "#### Plots of results ####\n",
    "plt.figure()\n",
    "plt.plot(y_test,'-o',  label = \"Data\")\n",
    "plt.plot(predictions_ada,'-*', label = \"Ada Boost RF\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.4, Poly nominal regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin = LinearRegression()\n",
    "\n",
    "model_lin.fit(X_train,y_train)\n",
    "\n",
    "predictions_lin = model_lin.predict(X_test)\n",
    "\n",
    "error = mean_squared_error(predictions_lin, y_test) # Mean squared error\n",
    "\n",
    "score = model_lin.score(X_test,y_test)              # Variance / score\n",
    "\n",
    "# Prediction and model assessment by MSE and R2\n",
    "mse_lin = mean_squared_error(predictions_lin,y_test)\n",
    "r2_lin = r2_score(predictions_lin,y_test)\n",
    "\n",
    "\n",
    "#### Plots of results ####\n",
    "plt.figure()\n",
    "plt.plot(y_test,'-o',  label = \"Data\")\n",
    "plt.plot(predictions_lin,'-*', label = \"Linear regression\")\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "xgb_rnn_pytorch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
